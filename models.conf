{
    "llama-2-7b": {
        "file": "models/llama-2-7b-chat.gguf",
        "max_tokens": 4096,
        "model_type": "llama"
    },
    "llama-2-13b": {
        "file": "models/llama-2-13b-chat.gguf",
        "max_tokens": 4096,
        "model_type": "llama"
    },
    "mistral-7b": {
        "file": "models/mistral-7b-instruct.gguf",
        "max_tokens": 8192,
        "model_type": "mistral"
    },
    "openchat": {
        "file": "openchat",
        "max_tokens": 512,
        "model_type": "ollama"
    }
}
